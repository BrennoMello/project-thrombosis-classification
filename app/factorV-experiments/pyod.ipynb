{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models.auto_encoder import AutoEncoder\n",
    "from data import read_dataset_v\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = read_dataset_v()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_balanced_folds(X, Y, percentage, rs, at='target'): \n",
    "    size_minority = min(Counter(Y).values())\n",
    "\n",
    "    X[at] = Y\n",
    "    \n",
    "    # surffle\n",
    "    X = shuffle(X, random_state=rs)\n",
    "\n",
    "    p = np.ceil(size_minority * percentage).astype('int')\n",
    "    train = []\n",
    "    test = []\n",
    "    for classe in X[at].unique():\n",
    "        \n",
    "        df_class = X[X[at] == classe]\n",
    "        \n",
    "        test.append(df_class.iloc[:p])\n",
    "        train.append(df_class.iloc[p:])\n",
    "        \n",
    "    df_train = pd.concat(train)\n",
    "    df_test = pd.concat(test)\n",
    "\n",
    "    y_train = df_train[at]\n",
    "    y_test = df_test[at]\n",
    "        \n",
    "    x_train = df_train.drop([at], axis=1)\n",
    "    x_test = df_test.drop([at], axis=1)   \n",
    "    \n",
    "    return x_train, y_train, x_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_raw, y_train_raw, x_test_raw, y_test_raw = create_balanced_folds(x, y, 0.15, 10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.utils.utility import standardizer\n",
    "\n",
    "X_train_norm, X_test_norm = standardizer(x_train_raw, x_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_50 (Dense)            (None, 7)                 56        \n",
      "                                                                 \n",
      " dropout_43 (Dropout)        (None, 7)                 0         \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 7)                 56        \n",
      "                                                                 \n",
      " dropout_44 (Dropout)        (None, 7)                 0         \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 15)                120       \n",
      "                                                                 \n",
      " dropout_45 (Dropout)        (None, 15)                0         \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 10)                160       \n",
      "                                                                 \n",
      " dropout_46 (Dropout)        (None, 10)                0         \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 2)                 22        \n",
      "                                                                 \n",
      " dropout_47 (Dropout)        (None, 2)                 0         \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 10)                30        \n",
      "                                                                 \n",
      " dropout_48 (Dropout)        (None, 10)                0         \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 15)                165       \n",
      "                                                                 \n",
      " dropout_49 (Dropout)        (None, 15)                0         \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 7)                 112       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 721\n",
      "Trainable params: 721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/600\n",
      "37/37 [==============================] - 3s 17ms/step - loss: 2.7073 - val_loss: 2.0253\n",
      "Epoch 2/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.1352 - val_loss: 1.7827\n",
      "Epoch 3/600\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.8844 - val_loss: 1.6204\n",
      "Epoch 4/600\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.6959 - val_loss: 1.4998\n",
      "Epoch 5/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.5673 - val_loss: 1.4034\n",
      "Epoch 6/600\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.4743 - val_loss: 1.3320\n",
      "Epoch 7/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.4055 - val_loss: 1.2782\n",
      "Epoch 8/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.3482 - val_loss: 1.2354\n",
      "Epoch 9/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.3055 - val_loss: 1.2008\n",
      "Epoch 10/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.2714 - val_loss: 1.1726\n",
      "Epoch 11/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.2442 - val_loss: 1.1499\n",
      "Epoch 12/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.2202 - val_loss: 1.1311\n",
      "Epoch 13/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.2004 - val_loss: 1.1149\n",
      "Epoch 14/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.1824 - val_loss: 1.1010\n",
      "Epoch 15/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.1675 - val_loss: 1.0891\n",
      "Epoch 16/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.1548 - val_loss: 1.0789\n",
      "Epoch 17/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.1462 - val_loss: 1.0699\n",
      "Epoch 18/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.1370 - val_loss: 1.0619\n",
      "Epoch 19/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.1286 - val_loss: 1.0548\n",
      "Epoch 20/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.1225 - val_loss: 1.0484\n",
      "Epoch 21/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.1146 - val_loss: 1.0427\n",
      "Epoch 22/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.1112 - val_loss: 1.0375\n",
      "Epoch 23/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.1045 - val_loss: 1.0328\n",
      "Epoch 24/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.1001 - val_loss: 1.0285\n",
      "Epoch 25/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0939 - val_loss: 1.0245\n",
      "Epoch 26/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0904 - val_loss: 1.0211\n",
      "Epoch 27/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0881 - val_loss: 1.0178\n",
      "Epoch 28/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0844 - val_loss: 1.0148\n",
      "Epoch 29/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0809 - val_loss: 1.0120\n",
      "Epoch 30/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0777 - val_loss: 1.0094\n",
      "Epoch 31/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0751 - val_loss: 1.0071\n",
      "Epoch 32/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0752 - val_loss: 1.0047\n",
      "Epoch 33/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0719 - val_loss: 1.0027\n",
      "Epoch 34/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0684 - val_loss: 1.0007\n",
      "Epoch 35/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0668 - val_loss: 0.9989\n",
      "Epoch 36/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 0.9972\n",
      "Epoch 37/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0639 - val_loss: 0.9956\n",
      "Epoch 38/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0618 - val_loss: 0.9940\n",
      "Epoch 39/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0595 - val_loss: 0.9926\n",
      "Epoch 40/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0594 - val_loss: 0.9912\n",
      "Epoch 41/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0571 - val_loss: 0.9899\n",
      "Epoch 42/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0553 - val_loss: 0.9887\n",
      "Epoch 43/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0541 - val_loss: 0.9875\n",
      "Epoch 44/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0549 - val_loss: 0.9863\n",
      "Epoch 45/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0523 - val_loss: 0.9852\n",
      "Epoch 46/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0518 - val_loss: 0.9843\n",
      "Epoch 47/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0500 - val_loss: 0.9832\n",
      "Epoch 48/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0500 - val_loss: 0.9822\n",
      "Epoch 49/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0479 - val_loss: 0.9813\n",
      "Epoch 50/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0466 - val_loss: 0.9805\n",
      "Epoch 51/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0455 - val_loss: 0.9797\n",
      "Epoch 52/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0462 - val_loss: 0.9788\n",
      "Epoch 53/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0456 - val_loss: 0.9780\n",
      "Epoch 54/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0443 - val_loss: 0.9773\n",
      "Epoch 55/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0431 - val_loss: 0.9765\n",
      "Epoch 56/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0428 - val_loss: 0.9758\n",
      "Epoch 57/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0425 - val_loss: 0.9751\n",
      "Epoch 58/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0419 - val_loss: 0.9744\n",
      "Epoch 59/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0416 - val_loss: 0.9738\n",
      "Epoch 60/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0400 - val_loss: 0.9732\n",
      "Epoch 61/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0394 - val_loss: 0.9726\n",
      "Epoch 62/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0386 - val_loss: 0.9720\n",
      "Epoch 63/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0385 - val_loss: 0.9714\n",
      "Epoch 64/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0379 - val_loss: 0.9708\n",
      "Epoch 65/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0372 - val_loss: 0.9703\n",
      "Epoch 66/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0372 - val_loss: 0.9698\n",
      "Epoch 67/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0359 - val_loss: 0.9693\n",
      "Epoch 68/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0357 - val_loss: 0.9688\n",
      "Epoch 69/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0348 - val_loss: 0.9683\n",
      "Epoch 70/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0349 - val_loss: 0.9678\n",
      "Epoch 71/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0340 - val_loss: 0.9673\n",
      "Epoch 72/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0342 - val_loss: 0.9669\n",
      "Epoch 73/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0329 - val_loss: 0.9665\n",
      "Epoch 74/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0324 - val_loss: 0.9660\n",
      "Epoch 75/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0327 - val_loss: 0.9656\n",
      "Epoch 76/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0331 - val_loss: 0.9652\n",
      "Epoch 77/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0317 - val_loss: 0.9648\n",
      "Epoch 78/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0304 - val_loss: 0.9644\n",
      "Epoch 79/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0304 - val_loss: 0.9640\n",
      "Epoch 80/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0306 - val_loss: 0.9637\n",
      "Epoch 81/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0299 - val_loss: 0.9633\n",
      "Epoch 82/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0305 - val_loss: 0.9630\n",
      "Epoch 83/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0298 - val_loss: 0.9626\n",
      "Epoch 84/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0293 - val_loss: 0.9622\n",
      "Epoch 85/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0274 - val_loss: 0.9619\n",
      "Epoch 86/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0288 - val_loss: 0.9616\n",
      "Epoch 87/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0278 - val_loss: 0.9612\n",
      "Epoch 88/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0278 - val_loss: 0.9609\n",
      "Epoch 89/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0269 - val_loss: 0.9606\n",
      "Epoch 90/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0267 - val_loss: 0.9603\n",
      "Epoch 91/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0265 - val_loss: 0.9600\n",
      "Epoch 92/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0259 - val_loss: 0.9597\n",
      "Epoch 93/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0257 - val_loss: 0.9594\n",
      "Epoch 94/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0257 - val_loss: 0.9591\n",
      "Epoch 95/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0256 - val_loss: 0.9589\n",
      "Epoch 96/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0241 - val_loss: 0.9586\n",
      "Epoch 97/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0243 - val_loss: 0.9583\n",
      "Epoch 98/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0243 - val_loss: 0.9581\n",
      "Epoch 99/600\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 1.0242 - val_loss: 0.9579\n",
      "Epoch 100/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0240 - val_loss: 0.9576\n",
      "Epoch 101/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0243 - val_loss: 0.9573\n",
      "Epoch 102/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0236 - val_loss: 0.9571\n",
      "Epoch 103/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0239 - val_loss: 0.9568\n",
      "Epoch 104/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0231 - val_loss: 0.9566\n",
      "Epoch 105/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0231 - val_loss: 0.9564\n",
      "Epoch 106/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0226 - val_loss: 0.9561\n",
      "Epoch 107/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0225 - val_loss: 0.9559\n",
      "Epoch 108/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0227 - val_loss: 0.9557\n",
      "Epoch 109/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0216 - val_loss: 0.9555\n",
      "Epoch 110/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0217 - val_loss: 0.9552\n",
      "Epoch 111/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0219 - val_loss: 0.9550\n",
      "Epoch 112/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0210 - val_loss: 0.9548\n",
      "Epoch 113/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0211 - val_loss: 0.9546\n",
      "Epoch 114/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0205 - val_loss: 0.9544\n",
      "Epoch 115/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0203 - val_loss: 0.9542\n",
      "Epoch 116/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0207 - val_loss: 0.9540\n",
      "Epoch 117/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0202 - val_loss: 0.9538\n",
      "Epoch 118/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0198 - val_loss: 0.9537\n",
      "Epoch 119/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0199 - val_loss: 0.9535\n",
      "Epoch 120/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0193 - val_loss: 0.9533\n",
      "Epoch 121/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0191 - val_loss: 0.9531\n",
      "Epoch 122/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0193 - val_loss: 0.9530\n",
      "Epoch 123/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0188 - val_loss: 0.9528\n",
      "Epoch 124/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0192 - val_loss: 0.9526\n",
      "Epoch 125/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0182 - val_loss: 0.9525\n",
      "Epoch 126/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0189 - val_loss: 0.9523\n",
      "Epoch 127/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0184 - val_loss: 0.9521\n",
      "Epoch 128/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0181 - val_loss: 0.9520\n",
      "Epoch 129/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0178 - val_loss: 0.9518\n",
      "Epoch 130/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0180 - val_loss: 0.9517\n",
      "Epoch 131/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0181 - val_loss: 0.9515\n",
      "Epoch 132/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0173 - val_loss: 0.9513\n",
      "Epoch 133/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0175 - val_loss: 0.9512\n",
      "Epoch 134/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0177 - val_loss: 0.9510\n",
      "Epoch 135/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0174 - val_loss: 0.9509\n",
      "Epoch 136/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0168 - val_loss: 0.9508\n",
      "Epoch 137/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0173 - val_loss: 0.9506\n",
      "Epoch 138/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0169 - val_loss: 0.9505\n",
      "Epoch 139/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0169 - val_loss: 0.9503\n",
      "Epoch 140/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0164 - val_loss: 0.9502\n",
      "Epoch 141/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0164 - val_loss: 0.9501\n",
      "Epoch 142/600\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.0167 - val_loss: 0.9499\n",
      "Epoch 143/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0159 - val_loss: 0.9498\n",
      "Epoch 144/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0166 - val_loss: 0.9497\n",
      "Epoch 145/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0156 - val_loss: 0.9496\n",
      "Epoch 146/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0155 - val_loss: 0.9494\n",
      "Epoch 147/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0156 - val_loss: 0.9493\n",
      "Epoch 148/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0158 - val_loss: 0.9492\n",
      "Epoch 149/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0150 - val_loss: 0.9491\n",
      "Epoch 150/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0148 - val_loss: 0.9490\n",
      "Epoch 151/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0153 - val_loss: 0.9489\n",
      "Epoch 152/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0151 - val_loss: 0.9488\n",
      "Epoch 153/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0145 - val_loss: 0.9486\n",
      "Epoch 154/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0149 - val_loss: 0.9485\n",
      "Epoch 155/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0148 - val_loss: 0.9484\n",
      "Epoch 156/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0147 - val_loss: 0.9483\n",
      "Epoch 157/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0141 - val_loss: 0.9482\n",
      "Epoch 158/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0146 - val_loss: 0.9481\n",
      "Epoch 159/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0141 - val_loss: 0.9480\n",
      "Epoch 160/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0140 - val_loss: 0.9480\n",
      "Epoch 161/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0139 - val_loss: 0.9478\n",
      "Epoch 162/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0140 - val_loss: 0.9477\n",
      "Epoch 163/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0138 - val_loss: 0.9477\n",
      "Epoch 164/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0139 - val_loss: 0.9475\n",
      "Epoch 165/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0131 - val_loss: 0.9474\n",
      "Epoch 166/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0136 - val_loss: 0.9474\n",
      "Epoch 167/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0134 - val_loss: 0.9473\n",
      "Epoch 168/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0134 - val_loss: 0.9472\n",
      "Epoch 169/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0134 - val_loss: 0.9471\n",
      "Epoch 170/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0133 - val_loss: 0.9470\n",
      "Epoch 171/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0129 - val_loss: 0.9469\n",
      "Epoch 172/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0133 - val_loss: 0.9468\n",
      "Epoch 173/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0127 - val_loss: 0.9467\n",
      "Epoch 174/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0130 - val_loss: 0.9467\n",
      "Epoch 175/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0124 - val_loss: 0.9466\n",
      "Epoch 176/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0128 - val_loss: 0.9465\n",
      "Epoch 177/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0126 - val_loss: 0.9465\n",
      "Epoch 178/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0126 - val_loss: 0.9464\n",
      "Epoch 179/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0123 - val_loss: 0.9463\n",
      "Epoch 180/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0121 - val_loss: 0.9462\n",
      "Epoch 181/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0125 - val_loss: 0.9461\n",
      "Epoch 182/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0121 - val_loss: 0.9461\n",
      "Epoch 183/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0123 - val_loss: 0.9460\n",
      "Epoch 184/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0121 - val_loss: 0.9459\n",
      "Epoch 185/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0120 - val_loss: 0.9458\n",
      "Epoch 186/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0121 - val_loss: 0.9458\n",
      "Epoch 187/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0119 - val_loss: 0.9457\n",
      "Epoch 188/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0118 - val_loss: 0.9456\n",
      "Epoch 189/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0118 - val_loss: 0.9456\n",
      "Epoch 190/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0120 - val_loss: 0.9455\n",
      "Epoch 191/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0118 - val_loss: 0.9455\n",
      "Epoch 192/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0115 - val_loss: 0.9454\n",
      "Epoch 193/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0116 - val_loss: 0.9453\n",
      "Epoch 194/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0113 - val_loss: 0.9453\n",
      "Epoch 195/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0117 - val_loss: 0.9452\n",
      "Epoch 196/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0115 - val_loss: 0.9451\n",
      "Epoch 197/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0115 - val_loss: 0.9451\n",
      "Epoch 198/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0111 - val_loss: 0.9450\n",
      "Epoch 199/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0110 - val_loss: 0.9450\n",
      "Epoch 200/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0114 - val_loss: 0.9449\n",
      "Epoch 201/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0109 - val_loss: 0.9449\n",
      "Epoch 202/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0112 - val_loss: 0.9448\n",
      "Epoch 203/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0109 - val_loss: 0.9447\n",
      "Epoch 204/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0110 - val_loss: 0.9447\n",
      "Epoch 205/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0109 - val_loss: 0.9446\n",
      "Epoch 206/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0108 - val_loss: 0.9446\n",
      "Epoch 207/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0105 - val_loss: 0.9445\n",
      "Epoch 208/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0109 - val_loss: 0.9445\n",
      "Epoch 209/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0106 - val_loss: 0.9444\n",
      "Epoch 210/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0104 - val_loss: 0.9444\n",
      "Epoch 211/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0103 - val_loss: 0.9444\n",
      "Epoch 212/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0104 - val_loss: 0.9443\n",
      "Epoch 213/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0103 - val_loss: 0.9442\n",
      "Epoch 214/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0107 - val_loss: 0.9442\n",
      "Epoch 215/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0103 - val_loss: 0.9441\n",
      "Epoch 216/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0104 - val_loss: 0.9441\n",
      "Epoch 217/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0102 - val_loss: 0.9441\n",
      "Epoch 218/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0102 - val_loss: 0.9440\n",
      "Epoch 219/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0103 - val_loss: 0.9440\n",
      "Epoch 220/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0100 - val_loss: 0.9439\n",
      "Epoch 221/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0100 - val_loss: 0.9439\n",
      "Epoch 222/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0101 - val_loss: 0.9439\n",
      "Epoch 223/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0101 - val_loss: 0.9438\n",
      "Epoch 224/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0099 - val_loss: 0.9438\n",
      "Epoch 225/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0098 - val_loss: 0.9437\n",
      "Epoch 226/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0098 - val_loss: 0.9437\n",
      "Epoch 227/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0099 - val_loss: 0.9437\n",
      "Epoch 228/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0097 - val_loss: 0.9436\n",
      "Epoch 229/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0099 - val_loss: 0.9436\n",
      "Epoch 230/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0097 - val_loss: 0.9435\n",
      "Epoch 231/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0097 - val_loss: 0.9435\n",
      "Epoch 232/600\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.0098 - val_loss: 0.9435\n",
      "Epoch 233/600\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 1.0096 - val_loss: 0.9434\n",
      "Epoch 234/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0096 - val_loss: 0.9434\n",
      "Epoch 235/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0096 - val_loss: 0.9434\n",
      "Epoch 236/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0096 - val_loss: 0.9433\n",
      "Epoch 237/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0096 - val_loss: 0.9433\n",
      "Epoch 238/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0096 - val_loss: 0.9433\n",
      "Epoch 239/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0095 - val_loss: 0.9432\n",
      "Epoch 240/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0093 - val_loss: 0.9432\n",
      "Epoch 241/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0094 - val_loss: 0.9432\n",
      "Epoch 242/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0091 - val_loss: 0.9431\n",
      "Epoch 243/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0095 - val_loss: 0.9431\n",
      "Epoch 244/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0093 - val_loss: 0.9431\n",
      "Epoch 245/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0093 - val_loss: 0.9431\n",
      "Epoch 246/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0093 - val_loss: 0.9430\n",
      "Epoch 247/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0092 - val_loss: 0.9430\n",
      "Epoch 248/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0093 - val_loss: 0.9429\n",
      "Epoch 249/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0092 - val_loss: 0.9429\n",
      "Epoch 250/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0090 - val_loss: 0.9429\n",
      "Epoch 251/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0091 - val_loss: 0.9429\n",
      "Epoch 252/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0089 - val_loss: 0.9428\n",
      "Epoch 253/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0090 - val_loss: 0.9428\n",
      "Epoch 254/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0090 - val_loss: 0.9428\n",
      "Epoch 255/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0089 - val_loss: 0.9428\n",
      "Epoch 256/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0089 - val_loss: 0.9427\n",
      "Epoch 257/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0087 - val_loss: 0.9427\n",
      "Epoch 258/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0089 - val_loss: 0.9427\n",
      "Epoch 259/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0087 - val_loss: 0.9427\n",
      "Epoch 260/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0090 - val_loss: 0.9426\n",
      "Epoch 261/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0089 - val_loss: 0.9426\n",
      "Epoch 262/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0089 - val_loss: 0.9426\n",
      "Epoch 263/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0088 - val_loss: 0.9426\n",
      "Epoch 264/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0088 - val_loss: 0.9425\n",
      "Epoch 265/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0086 - val_loss: 0.9425\n",
      "Epoch 266/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0085 - val_loss: 0.9425\n",
      "Epoch 267/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0087 - val_loss: 0.9425\n",
      "Epoch 268/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0086 - val_loss: 0.9424\n",
      "Epoch 269/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0088 - val_loss: 0.9424\n",
      "Epoch 270/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0086 - val_loss: 0.9424\n",
      "Epoch 271/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0086 - val_loss: 0.9424\n",
      "Epoch 272/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0085 - val_loss: 0.9424\n",
      "Epoch 273/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0086 - val_loss: 0.9424\n",
      "Epoch 274/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0086 - val_loss: 0.9423\n",
      "Epoch 275/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0085 - val_loss: 0.9423\n",
      "Epoch 276/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0085 - val_loss: 0.9423\n",
      "Epoch 277/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0085 - val_loss: 0.9423\n",
      "Epoch 278/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0084 - val_loss: 0.9422\n",
      "Epoch 279/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0085 - val_loss: 0.9422\n",
      "Epoch 280/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0084 - val_loss: 0.9422\n",
      "Epoch 281/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0083 - val_loss: 0.9422\n",
      "Epoch 282/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0085 - val_loss: 0.9422\n",
      "Epoch 283/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0083 - val_loss: 0.9422\n",
      "Epoch 284/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0085 - val_loss: 0.9421\n",
      "Epoch 285/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0084 - val_loss: 0.9421\n",
      "Epoch 286/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0082 - val_loss: 0.9421\n",
      "Epoch 287/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0082 - val_loss: 0.9421\n",
      "Epoch 288/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0082 - val_loss: 0.9421\n",
      "Epoch 289/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0084 - val_loss: 0.9420\n",
      "Epoch 290/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0083 - val_loss: 0.9420\n",
      "Epoch 291/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0082 - val_loss: 0.9420\n",
      "Epoch 292/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0082 - val_loss: 0.9420\n",
      "Epoch 293/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0082 - val_loss: 0.9420\n",
      "Epoch 294/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0083 - val_loss: 0.9420\n",
      "Epoch 295/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0081 - val_loss: 0.9419\n",
      "Epoch 296/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0082 - val_loss: 0.9419\n",
      "Epoch 297/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0081 - val_loss: 0.9419\n",
      "Epoch 298/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0080 - val_loss: 0.9419\n",
      "Epoch 299/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0082 - val_loss: 0.9419\n",
      "Epoch 300/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0081 - val_loss: 0.9419\n",
      "Epoch 301/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0082 - val_loss: 0.9418\n",
      "Epoch 302/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0081 - val_loss: 0.9418\n",
      "Epoch 303/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0080 - val_loss: 0.9418\n",
      "Epoch 304/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0080 - val_loss: 0.9418\n",
      "Epoch 305/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0080 - val_loss: 0.9418\n",
      "Epoch 306/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0081 - val_loss: 0.9418\n",
      "Epoch 307/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0080 - val_loss: 0.9418\n",
      "Epoch 308/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0081 - val_loss: 0.9417\n",
      "Epoch 309/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0080 - val_loss: 0.9417\n",
      "Epoch 310/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0079 - val_loss: 0.9417\n",
      "Epoch 311/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0079 - val_loss: 0.9417\n",
      "Epoch 312/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0079 - val_loss: 0.9417\n",
      "Epoch 313/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0079 - val_loss: 0.9417\n",
      "Epoch 314/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0079 - val_loss: 0.9417\n",
      "Epoch 315/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0080 - val_loss: 0.9417\n",
      "Epoch 316/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0079 - val_loss: 0.9417\n",
      "Epoch 317/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0080 - val_loss: 0.9416\n",
      "Epoch 318/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0078 - val_loss: 0.9416\n",
      "Epoch 319/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0079 - val_loss: 0.9416\n",
      "Epoch 320/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0079 - val_loss: 0.9416\n",
      "Epoch 321/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0079 - val_loss: 0.9416\n",
      "Epoch 322/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0078 - val_loss: 0.9416\n",
      "Epoch 323/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0078 - val_loss: 0.9416\n",
      "Epoch 324/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0078 - val_loss: 0.9416\n",
      "Epoch 325/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0078 - val_loss: 0.9415\n",
      "Epoch 326/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0078 - val_loss: 0.9415\n",
      "Epoch 327/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0078 - val_loss: 0.9415\n",
      "Epoch 328/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0077 - val_loss: 0.9415\n",
      "Epoch 329/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0078 - val_loss: 0.9415\n",
      "Epoch 330/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0077 - val_loss: 0.9415\n",
      "Epoch 331/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0078 - val_loss: 0.9415\n",
      "Epoch 332/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0077 - val_loss: 0.9415\n",
      "Epoch 333/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0077 - val_loss: 0.9415\n",
      "Epoch 334/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0077 - val_loss: 0.9414\n",
      "Epoch 335/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0077 - val_loss: 0.9414\n",
      "Epoch 336/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0077 - val_loss: 0.9414\n",
      "Epoch 337/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0077 - val_loss: 0.9414\n",
      "Epoch 338/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0076 - val_loss: 0.9414\n",
      "Epoch 339/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0077 - val_loss: 0.9414\n",
      "Epoch 340/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0077 - val_loss: 0.9414\n",
      "Epoch 341/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0076 - val_loss: 0.9414\n",
      "Epoch 342/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0076 - val_loss: 0.9414\n",
      "Epoch 343/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0077 - val_loss: 0.9414\n",
      "Epoch 344/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0076 - val_loss: 0.9414\n",
      "Epoch 345/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0076 - val_loss: 0.9413\n",
      "Epoch 346/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0076 - val_loss: 0.9413\n",
      "Epoch 347/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0076 - val_loss: 0.9413\n",
      "Epoch 348/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0076 - val_loss: 0.9413\n",
      "Epoch 349/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0075 - val_loss: 0.9413\n",
      "Epoch 350/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0076 - val_loss: 0.9413\n",
      "Epoch 351/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0076 - val_loss: 0.9413\n",
      "Epoch 352/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0075 - val_loss: 0.9413\n",
      "Epoch 353/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0076 - val_loss: 0.9413\n",
      "Epoch 354/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0076 - val_loss: 0.9413\n",
      "Epoch 355/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0076 - val_loss: 0.9413\n",
      "Epoch 356/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0076 - val_loss: 0.9412\n",
      "Epoch 357/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0075 - val_loss: 0.9412\n",
      "Epoch 358/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0075 - val_loss: 0.9412\n",
      "Epoch 359/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0074 - val_loss: 0.9412\n",
      "Epoch 360/600\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 1.0075 - val_loss: 0.9412\n",
      "Epoch 361/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0075 - val_loss: 0.9412\n",
      "Epoch 362/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0075 - val_loss: 0.9412\n",
      "Epoch 363/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0075 - val_loss: 0.9412\n",
      "Epoch 364/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0075 - val_loss: 0.9412\n",
      "Epoch 365/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0075 - val_loss: 0.9412\n",
      "Epoch 366/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0074 - val_loss: 0.9412\n",
      "Epoch 367/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0075 - val_loss: 0.9412\n",
      "Epoch 368/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0074 - val_loss: 0.9412\n",
      "Epoch 369/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0075 - val_loss: 0.9411\n",
      "Epoch 370/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0075 - val_loss: 0.9411\n",
      "Epoch 371/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0074 - val_loss: 0.9411\n",
      "Epoch 372/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0074 - val_loss: 0.9411\n",
      "Epoch 373/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0074 - val_loss: 0.9411\n",
      "Epoch 374/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0074 - val_loss: 0.9411\n",
      "Epoch 375/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0073 - val_loss: 0.9411\n",
      "Epoch 376/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0074 - val_loss: 0.9411\n",
      "Epoch 377/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0073 - val_loss: 0.9411\n",
      "Epoch 378/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0074 - val_loss: 0.9411\n",
      "Epoch 379/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0074 - val_loss: 0.9411\n",
      "Epoch 380/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0074 - val_loss: 0.9411\n",
      "Epoch 381/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0073 - val_loss: 0.9411\n",
      "Epoch 382/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0074 - val_loss: 0.9410\n",
      "Epoch 383/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0074 - val_loss: 0.9411\n",
      "Epoch 384/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0074 - val_loss: 0.9411\n",
      "Epoch 385/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0073 - val_loss: 0.9410\n",
      "Epoch 386/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0073 - val_loss: 0.9410\n",
      "Epoch 387/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0074 - val_loss: 0.9410\n",
      "Epoch 388/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0073 - val_loss: 0.9410\n",
      "Epoch 389/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0073 - val_loss: 0.9410\n",
      "Epoch 390/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0073 - val_loss: 0.9410\n",
      "Epoch 391/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0073 - val_loss: 0.9410\n",
      "Epoch 392/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0073 - val_loss: 0.9410\n",
      "Epoch 393/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0073 - val_loss: 0.9410\n",
      "Epoch 394/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0073 - val_loss: 0.9410\n",
      "Epoch 395/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0073 - val_loss: 0.9410\n",
      "Epoch 396/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0073 - val_loss: 0.9410\n",
      "Epoch 397/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0073 - val_loss: 0.9410\n",
      "Epoch 398/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0073 - val_loss: 0.9410\n",
      "Epoch 399/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0072 - val_loss: 0.9410\n",
      "Epoch 400/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0073 - val_loss: 0.9410\n",
      "Epoch 401/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0072 - val_loss: 0.9409\n",
      "Epoch 402/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0073 - val_loss: 0.9409\n",
      "Epoch 403/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0073 - val_loss: 0.9410\n",
      "Epoch 404/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0073 - val_loss: 0.9409\n",
      "Epoch 405/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0073 - val_loss: 0.9409\n",
      "Epoch 406/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0072 - val_loss: 0.9409\n",
      "Epoch 407/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0072 - val_loss: 0.9409\n",
      "Epoch 408/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0072 - val_loss: 0.9409\n",
      "Epoch 409/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0072 - val_loss: 0.9409\n",
      "Epoch 410/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0072 - val_loss: 0.9409\n",
      "Epoch 411/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0072 - val_loss: 0.9409\n",
      "Epoch 412/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0072 - val_loss: 0.9409\n",
      "Epoch 413/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0072 - val_loss: 0.9409\n",
      "Epoch 414/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0072 - val_loss: 0.9409\n",
      "Epoch 415/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0072 - val_loss: 0.9409\n",
      "Epoch 416/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0072 - val_loss: 0.9409\n",
      "Epoch 417/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0072 - val_loss: 0.9409\n",
      "Epoch 418/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0072 - val_loss: 0.9409\n",
      "Epoch 419/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0072 - val_loss: 0.9409\n",
      "Epoch 420/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0072 - val_loss: 0.9409\n",
      "Epoch 421/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0072 - val_loss: 0.9409\n",
      "Epoch 422/600\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 1.0072 - val_loss: 0.9409\n",
      "Epoch 423/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0072 - val_loss: 0.9408\n",
      "Epoch 424/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0072 - val_loss: 0.9409\n",
      "Epoch 425/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0071 - val_loss: 0.9408\n",
      "Epoch 426/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0072 - val_loss: 0.9408\n",
      "Epoch 427/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0072 - val_loss: 0.9409\n",
      "Epoch 428/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0071 - val_loss: 0.9408\n",
      "Epoch 429/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0072 - val_loss: 0.9408\n",
      "Epoch 430/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0072 - val_loss: 0.9409\n",
      "Epoch 431/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0071 - val_loss: 0.9408\n",
      "Epoch 432/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0071 - val_loss: 0.9408\n",
      "Epoch 433/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0071 - val_loss: 0.9408\n",
      "Epoch 434/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0071 - val_loss: 0.9408\n",
      "Epoch 435/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0071 - val_loss: 0.9408\n",
      "Epoch 436/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0072 - val_loss: 0.9408\n",
      "Epoch 437/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0071 - val_loss: 0.9408\n",
      "Epoch 438/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0071 - val_loss: 0.9408\n",
      "Epoch 439/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0071 - val_loss: 0.9408\n",
      "Epoch 440/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0071 - val_loss: 0.9408\n",
      "Epoch 441/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0071 - val_loss: 0.9408\n",
      "Epoch 442/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0071 - val_loss: 0.9408\n",
      "Epoch 443/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0071 - val_loss: 0.9408\n",
      "Epoch 444/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0071 - val_loss: 0.9408\n",
      "Epoch 445/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0071 - val_loss: 0.9408\n",
      "Epoch 446/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0071 - val_loss: 0.9408\n",
      "Epoch 447/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0071 - val_loss: 0.9408\n",
      "Epoch 448/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0071 - val_loss: 0.9408\n",
      "Epoch 449/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0071 - val_loss: 0.9408\n",
      "Epoch 450/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0071 - val_loss: 0.9408\n",
      "Epoch 451/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0071 - val_loss: 0.9408\n",
      "Epoch 452/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0071 - val_loss: 0.9408\n",
      "Epoch 453/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0071 - val_loss: 0.9407\n",
      "Epoch 454/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0070 - val_loss: 0.9407\n",
      "Epoch 455/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0071 - val_loss: 0.9408\n",
      "Epoch 456/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0071 - val_loss: 0.9407\n",
      "Epoch 457/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0071 - val_loss: 0.9407\n",
      "Epoch 458/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0071 - val_loss: 0.9407\n",
      "Epoch 459/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0071 - val_loss: 0.9407\n",
      "Epoch 460/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0070 - val_loss: 0.9407\n",
      "Epoch 461/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0070 - val_loss: 0.9407\n",
      "Epoch 462/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0071 - val_loss: 0.9407\n",
      "Epoch 463/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0071 - val_loss: 0.9407\n",
      "Epoch 464/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0070 - val_loss: 0.9407\n",
      "Epoch 465/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0070 - val_loss: 0.9407\n",
      "Epoch 466/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0070 - val_loss: 0.9407\n",
      "Epoch 467/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0071 - val_loss: 0.9407\n",
      "Epoch 468/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0070 - val_loss: 0.9407\n",
      "Epoch 469/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0070 - val_loss: 0.9407\n",
      "Epoch 470/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0070 - val_loss: 0.9407\n",
      "Epoch 471/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0070 - val_loss: 0.9407\n",
      "Epoch 472/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0070 - val_loss: 0.9407\n",
      "Epoch 473/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0070 - val_loss: 0.9407\n",
      "Epoch 474/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0070 - val_loss: 0.9407\n",
      "Epoch 475/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0070 - val_loss: 0.9407\n",
      "Epoch 476/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0070 - val_loss: 0.9407\n",
      "Epoch 477/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0070 - val_loss: 0.9407\n",
      "Epoch 478/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0070 - val_loss: 0.9407\n",
      "Epoch 479/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0070 - val_loss: 0.9407\n",
      "Epoch 480/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0070 - val_loss: 0.9407\n",
      "Epoch 481/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0070 - val_loss: 0.9407\n",
      "Epoch 482/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0070 - val_loss: 0.9407\n",
      "Epoch 483/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0070 - val_loss: 0.9407\n",
      "Epoch 484/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0070 - val_loss: 0.9407\n",
      "Epoch 485/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0070 - val_loss: 0.9407\n",
      "Epoch 486/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0070 - val_loss: 0.9407\n",
      "Epoch 487/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0070 - val_loss: 0.9407\n",
      "Epoch 488/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0070 - val_loss: 0.9407\n",
      "Epoch 489/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0070 - val_loss: 0.9407\n",
      "Epoch 490/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0070 - val_loss: 0.9407\n",
      "Epoch 491/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0070 - val_loss: 0.9407\n",
      "Epoch 492/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0070 - val_loss: 0.9407\n",
      "Epoch 493/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0070 - val_loss: 0.9406\n",
      "Epoch 494/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0070 - val_loss: 0.9407\n",
      "Epoch 495/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0070 - val_loss: 0.9406\n",
      "Epoch 496/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0070 - val_loss: 0.9406\n",
      "Epoch 497/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0070 - val_loss: 0.9406\n",
      "Epoch 498/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0070 - val_loss: 0.9406\n",
      "Epoch 499/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0070 - val_loss: 0.9407\n",
      "Epoch 500/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0070 - val_loss: 0.9406\n",
      "Epoch 501/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0070 - val_loss: 0.9406\n",
      "Epoch 502/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0070 - val_loss: 0.9407\n",
      "Epoch 503/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0070 - val_loss: 0.9406\n",
      "Epoch 504/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0070 - val_loss: 0.9406\n",
      "Epoch 505/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0070 - val_loss: 0.9406\n",
      "Epoch 506/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0070 - val_loss: 0.9406\n",
      "Epoch 507/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0070 - val_loss: 0.9406\n",
      "Epoch 508/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0070 - val_loss: 0.9406\n",
      "Epoch 509/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0070 - val_loss: 0.9406\n",
      "Epoch 510/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 511/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 512/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 513/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0070 - val_loss: 0.9406\n",
      "Epoch 514/600\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 515/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 516/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 517/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 518/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0070 - val_loss: 0.9406\n",
      "Epoch 519/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0070 - val_loss: 0.9406\n",
      "Epoch 520/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 521/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 522/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 523/600\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 524/600\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 525/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 526/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 527/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 528/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 529/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 530/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 531/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 532/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 533/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 534/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 535/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 536/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 537/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 538/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 539/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 540/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 541/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 542/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 543/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 544/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 545/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 546/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 547/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 548/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 549/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 550/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 551/600\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 552/600\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 553/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 554/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 555/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 556/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 557/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 558/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 559/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 560/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 561/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 562/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 563/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 564/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 565/600\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 566/600\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 567/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 568/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 569/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 570/600\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 571/600\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 572/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 573/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0069 - val_loss: 0.9405\n",
      "Epoch 574/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0069 - val_loss: 0.9406\n",
      "Epoch 575/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0069 - val_loss: 0.9405\n",
      "Epoch 576/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0069 - val_loss: 0.9405\n",
      "Epoch 577/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0069 - val_loss: 0.9405\n",
      "Epoch 578/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0069 - val_loss: 0.9405\n",
      "Epoch 579/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0069 - val_loss: 0.9405\n",
      "Epoch 580/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0069 - val_loss: 0.9405\n",
      "Epoch 581/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0069 - val_loss: 0.9405\n",
      "Epoch 582/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0069 - val_loss: 0.9405\n",
      "Epoch 583/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0069 - val_loss: 0.9405\n",
      "Epoch 584/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0069 - val_loss: 0.9405\n",
      "Epoch 585/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0069 - val_loss: 0.9405\n",
      "Epoch 586/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0069 - val_loss: 0.9405\n",
      "Epoch 587/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0069 - val_loss: 0.9405\n",
      "Epoch 588/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0069 - val_loss: 0.9405\n",
      "Epoch 589/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0069 - val_loss: 0.9405\n",
      "Epoch 590/600\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 1.0069 - val_loss: 0.9405\n",
      "Epoch 591/600\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.0069 - val_loss: 0.9405\n",
      "Epoch 592/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0069 - val_loss: 0.9405\n",
      "Epoch 593/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0068 - val_loss: 0.9405\n",
      "Epoch 594/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0068 - val_loss: 0.9405\n",
      "Epoch 595/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0068 - val_loss: 0.9405\n",
      "Epoch 596/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0068 - val_loss: 0.9405\n",
      "Epoch 597/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0068 - val_loss: 0.9405\n",
      "Epoch 598/600\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0068 - val_loss: 0.9405\n",
      "Epoch 599/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0068 - val_loss: 0.9405\n",
      "Epoch 600/600\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0068 - val_loss: 0.9405\n",
      "41/41 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AutoEncoder(batch_size=32, contamination=0.05, dropout_rate=0.2, epochs=600,\n",
       "      hidden_activation='relu', hidden_neurons=[15, 10, 2, 10, 15],\n",
       "      l2_regularizer=0.1,\n",
       "      loss=<function mean_squared_error at 0x7fa0e5cd45e0>,\n",
       "      optimizer='adam', output_activation='sigmoid', preprocessing=True,\n",
       "      random_state=None, validation_size=0.1, verbose=1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atcdr = AutoEncoder(epochs=600, contamination=0.05, hidden_neurons =[15, 10, 2, 10, 15])\n",
    "atcdr.fit(x_train_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 1237, 1: 66})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(atcdr.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.86318192, 2.39864551, 1.86856813, 1.7432144 , 1.13851118,\n",
       "       2.2798784 , 1.7221694 , 1.91722083, 2.45006753, 1.95711604,\n",
       "       3.64032817, 1.69997512, 1.9184544 , 1.26664541])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred = atcdr.predict(x_test_raw)\n",
    "y_test_score_pred = atcdr.decision_function(x_test_raw) \n",
    "y_test_score_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brenno/.pyenv/versions/3.8.14/envs/ipkernel/lib/python3.8/site-packages/pyod/models/base.py:410: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:03:37] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"n_components\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBOD(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "   colsample_bytree=1,\n",
       "   estimator_list=[KNN(algorithm='auto', contamination=0.1, leaf_size=30, method='largest',\n",
       "  metric='minkowski', metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
       "  radius=1.0), LOF(algorithm='auto', contamination=0.1, leaf_size=30, metric='minkowski',\n",
       "  metric_params=None, n_jobs=1, n_neighbors=1, no..._features=1.0,\n",
       "    max_samples='auto', n_estimators=200, n_jobs=1, random_state=100,\n",
       "    verbose=0)],\n",
       "   gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "   min_child_weight=1, n_estimators=100, n_jobs=1, nthread=None,\n",
       "   objective='binary:logistic', random_state=100, reg_alpha=0,\n",
       "   reg_lambda=1, scale_pos_weight=1, silent=True,\n",
       "   standardization_flag_list=[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False],\n",
       "   subsample=1)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyod.models.xgbod import XGBOD\n",
    "xgbod = XGBOD(n_components=10, random_state=100) \n",
    "xgbod.fit(x_train_raw, y_train_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05431375, 0.0226093 , 0.03901829, 0.01540772, 0.00375976,\n",
       "       0.0326301 , 0.0063637 , 0.02441703, 0.11061703, 0.04983323,\n",
       "       0.04258086, 0.02165323, 0.03383661, 0.02127785], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred = xgbod.predict(x_test_raw)  # outlier labels (0 or 1)\n",
    "y_test_scores = xgbod.decision_function(x_test_raw) # outlier scores\n",
    "y_test_scores  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 1287, 1: 16})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred = xgbod.labels_\n",
    "Counter(y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brenno/.pyenv/versions/3.8.14/envs/ipkernel/lib/python3.8/site-packages/pyod/models/base.py:410: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CBLOF(alpha=0.9, beta=5, check_estimator=False, clustering_estimator=None,\n",
       "   contamination=0.1, n_clusters=8, n_jobs=None, random_state=None,\n",
       "   use_weights=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyod.models.cblof import CBLOF\n",
    "cblof = CBLOF() \n",
    "cblof.fit(x_train_raw, y_train_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred = cblof.predict(x_test_raw)  # outlier labels (0 or 1)\n",
    "y_test_scores = cblof.decision_function(x_test_raw) # outlier scores\n",
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a3e734639ba1d9545ccaf20c4b4a2f4ed73d7e5b4b90eb8250ccb0114c4b7ca1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
